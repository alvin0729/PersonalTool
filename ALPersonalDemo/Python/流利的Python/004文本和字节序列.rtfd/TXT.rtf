{\rtf1\ansi\ansicpg936\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset134 PingFangSC-Regular;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 Menlo-Regular;
\f3\fnil\fcharset0 LucidaGrande;\f4\fnil\fcharset0 Monaco;\f5\fnil\fcharset77 ZapfDingbatsITC;
\f6\fnil\fcharset77 KohinoorDevanagari-Regular;\f7\fnil\fcharset0 Kefa-Regular;}
{\colortbl;\red255\green255\blue255;\red255\green0\blue255;\red170\green13\blue145;\red255\green255\blue255;
\red0\green0\blue0;\red196\green26\blue22;\red28\green0\blue207;\red0\green116\blue0;\red0\green0\blue255;
\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgenericrgb\c100000\c0\c100000;\csgenericrgb\c66500\c5200\c56900;\csgenericrgb\c100000\c100000\c100000;
\csgenericrgb\c0\c0\c0;\csgenericrgb\c77000\c10200\c8600;\csgenericrgb\c11000\c0\c81000;\csgenericrgb\c0\c45600\c0;\csgenericrgb\c0\c0\c100000;
\csgray\c0;\csgray\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
\paperw11900\paperh16840\margl1440\margr1440\vieww17840\viewh17560\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \
4.1 \'d7\'d6\'b7\'fb\'ce\'ca\'cc\'e2\
\pard\tx220\tx720\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\li720\fi-720\pardirnatural\partightenfactor0
\ls1\ilvl0\cf2 {\listtext	\'a1\'a4	}\'d7\'d6\'b7\'fb\'b5\'c4\'b1\'ea\'ca\'b6\'a3\'ac \'bc\'b4\'c2\'eb\'ce\'bb\'a3\'ac \'ca\'c7 0~1 114 111 \'b5\'c4\'ca\'fd\'d7\'d6\'a3\'a8 \'ca\'ae\'bd\'f8\'d6\'c6\'a3\'a9 \'a3\'ac\
{\listtext	\'a1\'a4	}\'d7\'d6\'b7\'fb\'b5\'c4\'be\'df\'cc\'e5\'b1\'ed\'ca\'f6\'c8\'a1\'be\'f6\'d3\'da\'cb\'f9\'d3\'c3\'b5\'c4\'b1\'e0\'c2\'eb\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 >>> s = 'caf\'a8\'a6'\
>>> len(s) # \uc0\u10122 \
4>\
>> b = s.encode('utf8') # \uc0\u10123 \
>>> b\
b'caf\\xc3\\xa9' # \uc0\u10124 \
>>> len(b) # \uc0\u10125 \
5\
>>> b.decode('utf8') # \uc0\u10126 \
'caf\'a8\'a6\
\uc0\u10102  'caf\'a8\'a6' \'d7\'d6\'b7\'fb\'b4\'ae\'d3\'d0 4 \'b8\'f6 Unicode \'d7\'d6\'b7\'fb\'a1\'a3\
\uc0\u10103  \'ca\'b9\'d3\'c3 UTF-8 \'b0\'d1 str \'b6\'d4\'cf\'f3\'b1\'e0\'c2\'eb\'b3\'c9 bytes \'b6\'d4\'cf\'f3\'a1\'a3\
\uc0\u10104  bytes \'d7\'d6\'c3\'e6\'c1\'bf\'d2\'d4 b \'bf\'aa\'cd\'b7\'a1\'a3\
\uc0\u10105  \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0 b \'d3\'d0 5 \'b8\'f6\'d7\'d6\'bd\'da\'a3\'a8 \'d4\'da UTF-8 \'d6\'d0\'a3\'ac \'a1\'b0\'a8\'a6\'a1\'b1\'b5\'c4\'c2\'eb\'ce\'bb\'b1\'e0\'c2\'eb\'b3\'c9\'c1\'bd\'b8\'f6\'d7\'d6\'bd\'da\'a3\'a9 \'a1\'a3\
\uc0\u10106  \'ca\'b9\'d3\'c3 UTF-8 \'b0\'d1 bytes \'b6\'d4\'cf\'f3\'bd\'e2\'c2\'eb\'b3\'c9 str \'b6\'d4\'cf\'f3\'a1\'a3\
\
\
4.2 \'d7\'d6\'bd\'da\'b8\'c5\'d2\'aa\
\
\'ca\'be\'c0\'fd 4-2 \'b0\'fc\'ba\'ac 5 \'b8\'f6\'d7\'d6\'bd\'da\'b5\'c4 bytes \'ba\'cd bytearray \'b6\'d4\'cf\'f3\
Python \'c4\'da\'d6\'c3\'c1\'cb\'c1\'bd\'d6\'d6\'bb\'f9\'b1\'be\'b5\'c4\'b6\'fe\'bd\'f8\'d6\'c6\'d0\'f2\'c1\'d0\'c0\'e0\'d0\'cd\'a3\'ba Python 3 \'d2\'fd\'c8\'eb\'b5\'c4\'b2\'bb\'bf\'c9\'b1\'e4bytes \'c0\'e0\'d0\'cd\'ba\'cd Python 2.6 \'cc\'ed\'bc\'d3\'b5\'c4\'bf\'c9\'b1\'e4 bytearray \'c0\'e0\'d0\'cd\'a1\'a3 \
\
bytes \'bb\'f2 bytearray \'b6\'d4\'cf\'f3\'b5\'c4\'b8\'f7\'b8\'f6\'d4\'aa\'cb\'d8\'ca\'c7\'bd\'e9\'d3\'da 0~255\'a3\'a8 \'ba\'ac\'a3\'a9 \'d6\'ae\'bc\'e4\'b5\'c4\'d5\'fb\'ca\'fd\
>>> cafe = bytes('caf\'a8\'a6', encoding='utf_8') \uc0\u10122 \
>>> cafe\
b'caf\\xc3\\xa9'\
>>> cafe[0] \uc0\u10123 \
99\
>>> cafe[:1] \uc0\u10124 \
b'c'\
>>> cafe_arr = bytearray(cafe)\
>>> cafe_arr \uc0\u10125 \
bytearray(b'caf\\xc3\\xa9')\
>>> cafe_arr[-1:] \uc0\u10126 \
bytearray(b'\\xa9')\
\
\uc0\u10103  \'b8\'f7\'b8\'f6\'d4\'aa\'cb\'d8\'ca\'c7 range(256) \'c4\'da\'b5\'c4\'d5\'fb\'ca\'fd\
\uc0\u10104  bytes \'b6\'d4\'cf\'f3\'b5\'c4\'c7\'d0\'c6\'ac\'bb\'b9\'ca\'c7 bytes \'b6\'d4\'cf\'f3\'a3\'ac \'bc\'b4\'ca\'b9\'ca\'c7\'d6\'bb\'d3\'d0\'d2\'bb\'b8\'f6\'d7\'d6\'bd\'da\'b5\'c4\'c7\'d0\'c6\'ac\'a1\'a3\
\uc0\u10105  bytearray \'b6\'d4\'cf\'f3\'c3\'bb\'d3\'d0\'d7\'d6\'c3\'e6\'c1\'bf\'be\'e4\'b7\'a8\'a3\'ac \'b6\'f8\'ca\'c7\'d2\'d4 bytearray() \'ba\'cd\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'d7\'d6\'c3\'e6\'c1\'bf\'b2\'ce\'ca\'fd\'b5\'c4\'d0\'ce\'ca\'bd\'cf\'d4\'ca\'be\'a1\'a3\
\uc0\u10106  bytearray \'b6\'d4\'cf\'f3\'b5\'c4\'c7\'d0\'c6\'ac\'bb\'b9\'ca\'c7 bytearray \'b6\'d4\'cf\'f3\'a1\'a3\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\fs24 \cf0 {{\NeXTGraphic Pasted Graphic.tiff \width12300 \height3580
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \
\
\'b8\'f7\'b8\'f6\'d7\'d6\'bd\'da\'b5\'c4\'d6\'b5\'bf\'c9\'c4\'dc\'bb\'e1\'ca\'b9\'d3\'c3\'cf\'c2\'c1\'d0\'c8\'fd\'d6\'d6\'b2\'bb\'cd\'ac\'b5\'c4\'b7\'bd\'ca\'bd\'cf\'d4\'ca\'be\'a1\'a3\
\pard\tx220\tx720\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\li720\fi-720\pardirnatural\partightenfactor0
\ls2\ilvl0\cf2 {\listtext	\'a1\'a4	}\'bf\'c9\'b4\'f2\'d3\'a1\'b5\'c4 ASCII \'b7\'b6\'ce\'a7\'c4\'da\'b5\'c4\'d7\'d6\'bd\'da\'a3\'a8 \'b4\'d3\'bf\'d5\'b8\'f1\'b5\'bd ~\'a3\'a9 \'a3\'ac \'ca\'b9\'d3\'c3 ASCII \'d7\'d6\'b7\'fb\'b1\'be\'c9\'ed\'a1\'a3\
{\listtext	\'a1\'a4	}\'d6\'c6\'b1\'ed\'b7\'fb\'a1\'a2 \'bb\'bb\'d0\'d0\'b7\'fb\'a1\'a2 \'bb\'d8\'b3\'b5\'b7\'fb\'ba\'cd \\ \'b6\'d4\'d3\'a6\'b5\'c4\'d7\'d6\'bd\'da\'a3\'ac \'ca\'b9\'d3\'c3\'d7\'aa\'d2\'e5\'d0\'f2\'c1\'d0\\t\'a1\'a2 \\n\'a1\'a2 \\r \'ba\'cd \\\\\'a1\'a3\
{\listtext	\'a1\'a4	}\'c6\'e4\'cb\'fb\'d7\'d6\'bd\'da\'b5\'c4\'d6\'b5\'a3\'ac \'ca\'b9\'d3\'c3\'ca\'ae\'c1\'f9\'bd\'f8\'d6\'c6\'d7\'aa\'d2\'e5\'d0\'f2\'c1\'d0\'a3\'a8 \'c0\'fd\'c8\'e7\'a3\'ac \\x00 \'ca\'c7\'bf\'d5\'d7\'d6\'bd\'da\'a3\'a9 \'a1\'a3\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 \
\'b3\'fd\'c1\'cb\'b8\'f1\'ca\'bd\'bb\'af\'b7\'bd\'b7\'a8\'a3\'a8 format \'ba\'cd format_map\'a3\'a9 \'ba\'cd\'bc\'b8\'b8\'f6\'b4\'a6\'c0\'ed Unicode \'ca\'fd\'be\'dd\'b5\'c4\
\'b7\'bd\'b7\'a8\'a3\'a8 \'b0\'fc\'c0\'a8\
casefold\'a1\'a2 isdecimal\'a1\'a2 isidentifier\'a1\'a2 isnumeric\'a1\'a2 isprintable\
\'ba\'cd encode\'a3\'a9 \'d6\'ae\'cd\'e2\'a3\'ac str \'c0\'e0\'d0\'cd\'b5\'c4\'c6\'e4\'cb\'fb\'b7\'bd\'b7\'a8\'b6\'bc\'d6\'a7\'b3\'d6 bytes \'ba\'cd bytearray \'c0\'e0\
\'d0\'cd\'a1\'a3 \
\
\'bd\'e2\'ce\'f6\'ca\'ae\'c1\'f9\'bd\'f8\'d6\'c6\'ca\'fd\'d7\'d6\'b6\'d4\'a3\'a8 \'ca\'fd\'d7\'d6\'b6\'d4\'d6\'ae\'bc\'e4\'b5\'c4\'bf\'d5\'b8\'f1\'ca\'c7\'bf\'c9\'d1\'a1\'b5\'c4\'a3\'a9 \'a3\'ac \'b9\'b9\'bd\'a8\'b6\'fe\'bd\'f8\'d6\'c6\'d0\'f2\'c1\'d0\'a3\'ba\
>>> bytes.fromhex('31 4B CE A9')\
b'1K\\xce\\xa9'\
\
\'b9\'b9\'bd\'a8 bytes \'bb\'f2 bytearray \'ca\'b5\'c0\'fd\
\pard\tx220\tx720\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\li720\fi-720\pardirnatural\partightenfactor0
\ls3\ilvl0\cf2 {\listtext	\'a1\'a4	}\'d2\'bb\'b8\'f6 str \'b6\'d4\'cf\'f3\'ba\'cd\'d2\'bb\'b8\'f6 encoding \'b9\'d8\'bc\'fc\'d7\'d6\'b2\'ce\'ca\'fd\'a1\'a3\
{\listtext	\'a1\'a4	}\'d2\'bb\'b8\'f6\'bf\'c9\'b5\'fc\'b4\'fa\'b6\'d4\'cf\'f3\'a3\'ac \'cc\'e1\'b9\'a9 0~255 \'d6\'ae\'bc\'e4\'b5\'c4\'ca\'fd\'d6\'b5\'a1\'a3\
{\listtext	\'a1\'a4	}\'d2\'bb\'b8\'f6\'d5\'fb\'ca\'fd\'a3\'ac \'ca\'b9\'d3\'c3\'bf\'d5\'d7\'d6\'bd\'da\'b4\'b4\'bd\'a8\'b6\'d4\'d3\'a6\'b3\'a4\'b6\'c8\'b5\'c4\'b6\'fe\'bd\'f8\'d6\'c6\'d0\'f2\'c1\'d0\'a1\'a3 [Python 3.5 \'bb\'e1\'b0\'d1\'d5\'e2\'b8\'f6\'b9\'b9\'d4\'ec\'b7\'bd\'b7\'a8\'b1\'ea\'bc\'c7\'ce\'aa\'a1\'b0\'b9\'fd\'ca\'b1\'b5\'c4\'a1\'b1\'a3\'ac Python 3.6 \'bb\'e1\'bd\'ab\'c6\'e4\'c9\'be\'b3\'fd\'a1\'a3 \'b2\'ce\'bc\'fb\'a1\'b0PEP 467\'a1\'aaMinor API improvements for binarysequences\'a1\'b1\'a3\'a8 https://www.python.org/dev/peps/pep-0467/\'a3\'a9 \'a1\'a3 ]\
{\listtext	\'a1\'a4	}\'d2\'bb\'b8\'f6\'ca\'b5\'cf\'d6\'c1\'cb\'bb\'ba\'b3\'e5\'d0\'ad\'d2\'e9\'b5\'c4\'b6\'d4\'cf\'f3\'a3\'a8 \'c8\'e7bytes\'a1\'a2 bytearray\'a1\'a2 memoryview\'a1\'a2 array.array\'a3\'a9 \'a3\'bb \'b4\'cb\'ca\'b1\'a3\'ac \'b0\'d1\'d4\'b4\'b6\'d4\'cf\'f3\'d6\'d0\'b5\'c4\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b8\'b4\'d6\'c6\'b5\'bd\'d0\'c2\'bd\'a8\'b5\'c4\'b6\'fe\'bd\'f8\'d6\'c6\'d0\'f2\'c1\'d0\'d6\'d0\'a1\'a3\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 \
\'ca\'be\'c0\'fd 4-3 \'ca\'b9\'d3\'c3\'ca\'fd\'d7\'e9\'d6\'d0\'b5\'c4\'d4\'ad\'ca\'bc\'ca\'fd\'be\'dd\'b3\'f5\'ca\'bc\'bb\'af bytes \'b6\'d4\'cf\'f3\
>>> import array\
>>> numbers = array.array('h', [-2, -1, 0, 1, 2]) \uc0\u10122 \
>>> octets = bytes(numbers) \uc0\u10123 \
>>> octets\
b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00' \uc0\u10124 \
\
\uc0\u10122  \'d6\'b8\'b6\'a8\'c0\'e0\'d0\'cd\'b4\'fa\'c2\'eb h\'a3\'ac \'b4\'b4\'bd\'a8\'d2\'bb\'b8\'f6\'b6\'cc\'d5\'fb\'ca\'fd\'a3\'a8 16 \'ce\'bb\'a3\'a9 \'ca\'fd\'d7\'e9\'a1\'a3\
\uc0\u10123  octets \'b1\'a3\'b4\'e6\'d7\'e9\'b3\'c9 numbers \'b5\'c4\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b5\'c4\'b8\'b1\'b1\'be\'a1\'a3\
\uc0\u10124  \'d5\'e2\'d0\'a9\'ca\'c7\'b1\'ed\'ca\'be\'c4\'c7 5 \'b8\'f6\'b6\'cc\'d5\'fb\'ca\'fd\'b5\'c4 10 \'b8\'f6\'d7\'d6\'bd\'da\'a1\'a3\
\
\'bd\'e1\'b9\'b9\'cc\'e5\'ba\'cd\'c4\'da\'b4\'e6\'ca\'d3\'cd\'bc\
memoryview \'c0\'e0\'b2\'bb\'ca\'c7\'d3\'c3\'d3\'da\'b4\'b4\'bd\'a8\'bb\'f2\'b4\'e6\'b4\'a2\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b5\'c4\'a3\'ac \'b6\'f8\
\'ca\'c7\'b9\'b2\'cf\'ed\'c4\'da\'b4\'e6\'a3\'ac \'c8\'c3\'c4\'e3\'b7\'c3\'ce\'ca\'c6\'e4\'cb\'fb\'b6\'fe\'bd\'f8\'d6\'c6\'d0\'f2\'c1\'d0\'a1\'a2 \'b4\'f2\'b0\'fc\'b5\'c4\'ca\'fd\'d7\'e9\'ba\'cd\'bb\'ba\'b3\'e5\'d6\'d0\'b5\'c4\'ca\'fd\'be\'dd\'c7\'d0\
\'c6\'ac\'a3\'ac \'b6\'f8\'ce\'de\'d0\'e8\'b8\'b4\'d6\'c6\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\
\
\'ca\'be\'c0\'fd 4-4 \'d5\'b9\'ca\'be\'c1\'cb\'c8\'e7\'ba\'ce\'ca\'b9\'d3\'c3 memoryview \'ba\'cd struct \'cc\'e1\'c8\'a1\'d2\'bb\'b8\'f6 GIF \'cd\'bc\'cf\'f1\'b5\'c4\'bf\'ed\'b6\'c8\'ba\'cd\'b8\'df\'b6\'c8\'a1\'a3\
>>> import struct\
>>> fmt = '<3s3sHH' # \uc0\u10122 \
>>> with open('filter.gif', 'rb') as fp:\
... img = memoryview(fp.read()) # \uc0\u10123 \
...\
>>> header = img[:10] # \uc0\u10124 \
>>> bytes(header) # \uc0\u10125 \
b'GIF89a+\\x02\\xe6\\x00'\
>>> struct.unpack(fmt, header) # \uc0\u10126 \
(b'GIF', b'89a', 555, 230)\
>>> del header # \uc0\u10127 \
>>> del img\
\
\uc0\u10102  \'bd\'e1\'b9\'b9\'cc\'e5\'b5\'c4\'b8\'f1\'ca\'bd\'a3\'ba < \'ca\'c7\'d0\'a1\'d7\'d6\'bd\'da\'d0\'f2\'a3\'ac 3s3s \'ca\'c7\'c1\'bd\'b8\'f6 3 \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a3\'ac HH \'ca\'c7\'c1\'bd\'b8\'f616 \'ce\'bb\'b6\'fe\'bd\'f8\'d6\'c6\'d5\'fb\'ca\'fd\'a1\'a3\
\uc0\u10104  \'a1\'ad\'a1\'ad\'c8\'bb\'ba\'f3\'ca\'b9\'d3\'c3\'cb\'fc\'b5\'c4\'c7\'d0\'c6\'ac\'d4\'d9\'b4\'b4\'bd\'a8\'d2\'bb\'b8\'f6 memoryview \'b6\'d4\'cf\'f3\'a3\'bb \'d5\'e2\'c0\'ef\'b2\'bb\'bb\'e1\'b8\'b4\'d6\'c6\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a1\'a3\
\uc0\u10105  \'d7\'aa\'bb\'bb\'b3\'c9\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a3\'ac \'d5\'e2\'d6\'bb\'ca\'c7\'ce\'aa\'c1\'cb\'cf\'d4\'ca\'be\'a3\'bb \'d5\'e2\'c0\'ef\'b8\'b4\'d6\'c6\'c1\'cb 10 \'d7\'d6\'bd\'da\'a1\'a3\
\uc0\u10106  \'b2\'f0\'b0\'fc memoryview \'b6\'d4\'cf\'f3\'a3\'ac \'b5\'c3\'b5\'bd\'d2\'bb\'b8\'f6\'d4\'aa\'d7\'e9\'a3\'ac \'b0\'fc\'ba\'ac\'c0\'e0\'d0\'cd\'a1\'a2 \'b0\'e6\'b1\'be\'a1\'a2 \'bf\'ed\'b6\'c8\'ba\'cd\'b8\'df\'b6\'c8\'a1\'a3\
\
\'c8\'e7\'b9\'fb\'c4\'e3\'be\'ad\'b3\'a3\'b6\'c1\'c8\'a1\'ba\'cd\'d0\'de\'b8\'c4\'b6\'fe\'bd\'f8\'d6\'c6\'ce\'c4\'bc\'fe\'a3\'ac \'bf\'c9\'d2\'d4\'d4\'c4\'b6\'c1 {\field{\*\fldinst{HYPERLINK "https://docs.python.org/3/library/mmap.html"}}{\fldrslt https://docs.python.org/3/library/mmap.html}}\'c0\'b4\'bd\'f8\'d2\'bb\'b2\'bd\'d1\'a7\'cf\'b0\'a1\'a3\
MemoryViews\'a1\'b1\'a3\'a8 {\field{\*\fldinst{HYPERLINK "https://docs.python.org/3/library/stdtypes.html#memory-views"}}{\fldrslt https://docs.python.org/3/library/stdtypes.html#memory-views}}\'a3\'a9\
\'ba\'cd\'a1\'b0struct\'a1\'aaInterpret bytes as packed binarydata\'a1\'b1\'a3\'a8 {\field{\*\fldinst{HYPERLINK "https://docs.python.org/3/library/struct.html"}}{\fldrslt https://docs.python.org/3/library/struct.html}}\'a3\'a9 \'a1\'a3\
\
4.3 \'bb\'f9\'b1\'be\'b5\'c4\'b1\'e0\'bd\'e2\'c2\'eb\'c6\'f7\
\'ca\'be\'c0\'fd 4-5 \'ca\'b9\'d3\'c3 3 \'b8\'f6\'b1\'e0\'bd\'e2\'c2\'eb\'c6\'f7\'b1\'e0\'c2\'eb\'d7\'d6\'b7\'fb\'b4\'ae\'a1\'b0El Ni\uc0\u241 o\'a1\'b1\'a3\'ac \'b5\'c3\'b5\'bd\'b5\'c4\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b2\'ee\'d2\'ec\'ba\'dc\'b4\'f3\
>>> for codec in ['latin_1', 'utf_8', 'utf_16']:\
... print(codec, 'El Ni\uc0\u241 o'.encode(codec), sep='\\t')\
...\
latin_1 b'El Ni\\xf1o'\
utf_8 b'El Ni\\xc3\\xb1o'\
utf_16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\
\
4.4 \'c1\'cb\'bd\'e2\'b1\'e0\'bd\'e2\'c2\'eb\'ce\'ca\'cc\'e2\
4.4.1 \'b4\'a6\'c0\'edUnicodeEncodeError\
>>> city = 'S\uc0\u227 o Paulo'\
>>> city.encode('utf_8') \uc0\u10122 \
b'S\\xc3\\xa3o Paulo'\
>>> city.encode('utf_16')\
b'\\xff\\xfeS\\x00\\xe3\\x00o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00'\
>>> city.encode('iso8859_1') \uc0\u10123 \
b'S\\xe3o Paulo'\
>>> city.encode('cp437') \uc0\u10124 \
Traceback (most recent call last):\
File "<stdin>", line 1, in <module>\
File "/.../lib/python3.4/encodings/cp437.py", line 12, in encode\
return codecs.charmap_encode(input,errors,encoding_map)\
UnicodeEncodeError: 'charmap' codec can't encode character '\\xe3' in\
position 1: character maps to <undefined>\
>>> city.encode('cp437', errors='ignore') \uc0\u10125 \
b'So Paulo'\
>>> city.encode('cp437', errors='replace') \uc0\u10126 \
b'S?o Paulo'\
>>> city.encode('cp437', errors='xmlcharrefreplace') \uc0\u10127 \
b'S\uc0\u227 o Paulo'\
\uc0\u10102  'utf_?' \'b1\'e0\'c2\'eb\'c4\'dc\'b4\'a6\'c0\'ed\'c8\'ce\'ba\'ce\'d7\'d6\'b7\'fb\'b4\'ae\'a1\'a3\
\uc0\u10103  'iso8859_1' \'b1\'e0\'c2\'eb\'d2\'b2\'c4\'dc\'b4\'a6\'c0\'ed\'d7\'d6\'b7\'fb\'b4\'ae 'S\u227 o Paulo'\'a1\'a3\
\uc0\u10104  'cp437' \'ce\'de\'b7\'a8\'b1\'e0\'c2\'eb '\u227 '\'a3\'a8 \'b4\'f8\'b2\'a8\'d0\'ce\'b7\'fb\'b5\'c4\'a1\'b0a\'a1\'b1\'a3\'a9 \'a1\'a3 \'c4\'ac\'c8\'cf\'b5\'c4\'b4\'ed\'ce\'f3\'b4\'a6\'c0\'ed\'b7\'bd\'ca\'bd'strict' \'c5\'d7\'b3\'f6 UnicodeEncodeError\'a1\'a3\
\uc0\u10105  error='ignore' \'b4\'a6\'c0\'ed\'b7\'bd\'ca\'bd\'c7\'c4\'ce\'de\'c9\'f9\'cf\'a2\'b5\'d8\'cc\'f8\'b9\'fd\'ce\'de\'b7\'a8\'b1\'e0\'c2\'eb\'b5\'c4\'d7\'d6\'b7\'fb\'a3\'bb \'d5\'e2\'d1\'f9\'d7\'f6\'cd\'a8\'b3\'a3\'ba\'dc\'ca\'c7\'b2\'bb\'cd\'d7\'a1\'a3\
\uc0\u10106  \'b1\'e0\'c2\'eb\'ca\'b1\'d6\'b8\'b6\'a8 error='replace'\'a3\'ac \'b0\'d1\'ce\'de\'b7\'a8\'b1\'e0\'c2\'eb\'b5\'c4\'d7\'d6\'b7\'fb\'cc\'e6\'bb\'bb\'b3\'c9 '?'\'a3\'bb \'ca\'fd\'be\'dd\'cb\'f0\'bb\'b5\'c1\'cb\'a3\'ac \'b5\'ab\'ca\'c7\'d3\'c3\'bb\'a7\'d6\'aa\'b5\'c0\'b3\'f6\'c1\'cb\'ce\'ca\'cc\'e2\'a1\'a3\
\uc0\u10107  'xmlcharrefreplace' \'b0\'d1\'ce\'de\'b7\'a8\'b1\'e0\'c2\'eb\'b5\'c4\'d7\'d6\'b7\'fb\'cc\'e6\'bb\'bb\'b3\'c9 XML\'ca\'b5\'cc\'e5\'a1\'a3\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f1\fs24 \cf0 {{\NeXTGraphic Pasted Graphic 1.tiff \width700 \height780
}¬}\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \'c4\'e3\'bf\'c9\'d2\'d4\'ce\'aa errors \'b2\'ce\
\'ca\'fd\'d7\'a2\'b2\'e1\'b6\'ee\'cd\'e2\'b5\'c4\'d7\'d6\'b7\'fb\'b4\'ae\'a3\'ac \'b7\'bd\'b7\'a8\'ca\'c7\'b0\'d1\'d2\'bb\'b8\'f6\'c3\'fb\'b3\'c6\'ba\'cd\'d2\'bb\'b8\'f6\'b4\'ed\'ce\'f3\'b4\'a6\'c0\'ed\'ba\'af\'ca\'fd\'b4\'ab\'b8\'f8\
codecs.register_error \'ba\'af\'ca\'fd\'a1\'a3 \'b2\'ce\'bc\'fb codecs.register_error\
\'ba\'af\'ca\'fd\'b5\'c4\'ce\'c4\'b5\'b5\
\'a3\'a8 https://docs.python.org/3/library/codecs.html#codecs.register_error\'a3\'a9 \'a1\'a3\
\
4.4.2 \'b4\'a6\'c0\'edUnicodeDecodeError\
\'ca\'be\'c0\'fd 4-7 \'b0\'d1\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'bd\'e2\'c2\'eb\'b3\'c9\'d7\'d6\'b7\'fb\'b4\'ae\'a3\'ba \'b3\'c9\'b9\'a6\'ba\'cd\'b4\'ed\'ce\'f3\'b4\'a6\'c0\'ed\
\
>>> octets = b'Montr\\xe9al' \uc0\u10122 \
>>> octets.decode('cp1252') \uc0\u10123 \
'Montr\'a8\'a6al'\
>>> octets.decode('iso8859_7') \uc0\u10124 \
'Montr\'a6\'c9al'\
>>> octets.decode('koi8_r') \uc0\u10125 \
'Montr\'a7\'aaal'\
>>> octets.decode('utf_8') \uc0\u10126 \
Traceback (most recent call last):\
File "<stdin>", line 1, in <module>\
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5:\
invalid continuation byte\
>>> octets.decode('utf_8', errors='replace') \uc0\u10127 \
'Montral\
\
\uc0\u10102  \'d5\'e2\'d0\'a9\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'ca\'c7\'ca\'b9\'d3\'c3 latin1 \'b1\'e0\'c2\'eb\'b5\'c4\'a1\'b0Montr\'a8\'a6al\'a1\'b1\'a3\'bb '\\xe9' \'d7\'d6\'bd\'da\'b6\'d4\'d3\'a6\'a1\'b0\'a8\'a6\'a1\'b1\'a1\'a3\
\uc0\u10103  \'bf\'c9\'d2\'d4\'ca\'b9\'d3\'c3 'cp1252'\'a3\'a8 Windows 1252\'a3\'a9 \'bd\'e2\'c2\'eb\'a3\'ac \'d2\'f2\'ce\'aa\'cb\'fc\'ca\'c7 latin1 \'b5\'c4\'d3\'d0\'d0\'a7\'b3\'ac\'bc\'af\'a1\'a3\
\uc0\u10104  ISO-8859-7 \'d3\'c3\'d3\'da\'b1\'e0\'c2\'eb\'cf\'a3\'c0\'b0\'ce\'c4\'a3\'ac \'d2\'f2\'b4\'cb\'ce\'de\'b7\'a8\'d5\'fd\'c8\'b7\'bd\'e2\'ca\'cd '\\xe9' \'d7\'d6\'bd\'da\'a3\'ac \'b6\'f8\'c7\'d2\'c3\'bb\'d3\'d0\'c5\'d7\'b3\'f6\'b4\'ed\'ce\'f3\'a1\'a3\
\uc0\u10105  KOI8-R \'d3\'c3\'d3\'da\'b1\'e0\'c2\'eb\'b6\'ed\'ce\'c4\'a3\'bb \'d5\'e2\'c0\'ef\'a3\'ac '\\xe9' \'b1\'ed\'ca\'be\'ce\'f7\'c0\'ef\'b6\'fb\'d7\'d6\'c4\'b8\'a1\'b0\'a7\'aa\'a1\'b1\'a1\'a3\
\
4.4.3 \'ca\'b9\'d3\'c3\'d4\'a4\'c6\'da\'d6\'ae\'cd\'e2\'b5\'c4\'b1\'e0\'c2\'eb\'bc\'d3\'d4\'d8\'c4\'a3\'bf\'e9\'ca\'b1\'c5\'d7\'b3\'f6\'b5\'c4SyntaxError\
\
\'bf\'c9\'d2\'d4\'d4\'da\'ce\'c4\'bc\'fe\'b6\'a5\'b2\'bf\'cc\'ed\'bc\'d3\'d2\'bb\'b8\'f6\'c9\'f1\'c6\'e6\'b5\'c4 coding \'d7\'a2\'ca\'cd\
\'ca\'be\'c0\'fd 4-8 ola.py\'a3\'ba \'a1\'b0\'c4\'e3\'ba\'c3\'a3\'ac \'ca\'c0\'bd\'e7\'a3\'a1 \'a1\'b1\'b5\'c4\'c6\'cf\'cc\'d1\'d1\'c0\'d3\'ef\'b0\'e6\
# coding: cp1252\
print('Ol\'a8\'a2, Mundo!')\
\
Python 3 \'d4\'ca\'d0\'ed\'d4\'da\'d4\'b4\'c2\'eb\'d6\'d0\'ca\'b9\'d3\'c3\'b7\'c7 ASCII \'b1\'ea\'ca\'b6\'b7\'fb\'a3\'ba\
>>> a\uc0\u231 \u227 o = 'PBR' # a\u231 \u227 o = stock\
>>> \'a6\'c5 = 10**-6 # \'a6\'c5 = epsilon\
\
4.4.4 \'c8\'e7\'ba\'ce\'d5\'d2\'b3\'f6\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b5\'c4\'b1\'e0\'c2\'eb\
\'cd\'b3\'d2\'bb\'d7\'d6\'b7\'fb\'b1\'e0\'c2\'eb\'d5\'ec\'b2\'e2\'b0\'fc Chardet\'a3\'a8 https://pypi.python.org/pypi/chardet\'a3\'a9 \'be\'cd\'ca\'c7\
\'d5\'e2\'d1\'f9\'b9\'a4\'d7\'f7\'b5\'c4\'a3\'ac \'cb\'fc\'c4\'dc\'ca\'b6\'b1\'f0\'cb\'f9\'d6\'a7\'b3\'d6\'b5\'c4 30 \'d6\'d6\'b1\'e0\'c2\'eb\'a1\'a3 Chardet \'ca\'c7\'d2\'bb\'b8\'f6 Python \'bf\'e2\
\
$ chardetect 04-text-byte.asciidoc\
04-text-byte.asciidoc: utf-8 with confidence 0.99\
\
4.4.5 BOM\'a3\'ba \'d3\'d0\'d3\'c3\'b5\'c4\'b9\'ed\'b7\'fb\
>>> u16 = 'El Ni\uc0\u241 o'.encode('utf_16')\
>>> u16\
b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\
\
 b'\\xff\\xfe'\'a1\'a3 \'d5\'e2\'ca\'c7 BOM\'a3\'ac \'bc\'b4\'d7\'d6\'bd\'da\'d0\'f2\'b1\'ea\'bc\'c7\'a3\'a8 byte-order\
mark\'a3\'a9 \'a3\'ac \'d6\'b8\'c3\'f7\'b1\'e0\'c2\'eb\'ca\'b1\'ca\'b9\'d3\'c3 Intel CPU \'b5\'c4\'d0\'a1\'d7\'d6\'bd\'da\'d0\'f2\'a1\'a3\
\
\'d4\'da\'d0\'a1\'d7\'d6\'bd\'da\'d0\'f2\'c9\'e8\'b1\'b8\'d6\'d0\'a3\'ac \'b8\'f7\'b8\'f6\'c2\'eb\'ce\'bb\'b5\'c4\'d7\'ee\'b5\'cd\'d3\'d0\'d0\'a7\'d7\'d6\'bd\'da\'d4\'da\'c7\'b0\'c3\'e6\'a3\'ba \'d7\'d6\'c4\'b8 'E' \'b5\'c4\'c2\'eb\'ce\'bb\
\'ca\'c7 U+0045\'a3\'a8 \'ca\'ae\'bd\'f8\'d6\'c6\'ca\'fd 69\'a3\'a9 \'a3\'ac \'d4\'da\'d7\'d6\'bd\'da\'c6\'ab\'d2\'c6\'b5\'c4\'b5\'da 2 \'ce\'bb\'ba\'cd\'b5\'da 3 \'ce\'bb\'b1\'e0\'c2\'eb\'ce\'aa 69 \'ba\'cd\
0\'a1\'a3\
>>> list(u16)\
[255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\
\
\'d4\'da\'b4\'f3\'d7\'d6\'bd\'da\'d0\'f2 CPU \'d6\'d0\'a3\'ac \'b1\'e0\'c2\'eb\'cb\'b3\'d0\'f2\'ca\'c7\'cf\'e0\'b7\'b4\'b5\'c4\'a3\'bb 'E' \'b1\'e0\'c2\'eb\'ce\'aa 0 \'ba\'cd 69\'a1\'a3\
>>> u16le = 'El Ni\uc0\u241 o'.encode('utf_16le')\
>>> list(u16le)\
[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\
>>> u16be = 'El Ni\uc0\u241 o'.encode('utf_16be')\
>>> list(u16be)\
[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]\
\
UTF-16LE\'a3\'ac \'cf\'d4\'ca\'bd\'d6\'b8\'c3\'f7\'ca\'b9\'d3\'c3\'d0\'a1\'d7\'d6\'bd\'da\'d0\'f2\'a3\'bb UTF-16BE\'a3\'ac\'cf\'d4\'ca\'bd\'d6\'b8\'c3\'f7\'ca\'b9\'d3\'c3\'b4\'f3\'d7\'d6\'bd\'da\'d0\'f2\'a1\'a3 \
\
4.5 \'b4\'a6\'c0\'ed\'ce\'c4\'b1\'be\'ce\'c4\'bc\'fe\
>>> fp = open('cafe.txt', 'w', encoding='utf_8')\
>>> fp \uc0\u10122 \
<_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'>\
>>> fp.write('caf\'a8\'a6')\
4 \uc0\u10123 \
>>> fp.close()\
>>> import os\
>>> os.stat('cafe.txt').st_size\
5 \uc0\u10124 \
>>> fp2 = open('cafe.txt')\
>>> fp2 \uc0\u10125 \
<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'>\
>>> fp2.encoding \uc0\u10126 \
'cp1252'\
>>> fp2.read()\
'caf\uc0\u195 \u169 ' \u10127 \
>>> fp3 = open('cafe.txt', encoding='utf_8') \uc0\u10128 \
>>> fp3\
<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='utf_8'>\
>>> fp3.read()\
'caf\'a8\'a6' \uc0\u10129 \
>>> fp4 = open('cafe.txt', 'rb') \uc0\u10130 \
>>> fp4\
<_io.BufferedReader name='cafe.txt'> \uc0\u10131 \
>>> fp4.read() \uc0\u9451 \
b'caf\\xc3\\xa9'\
\
\uc0\u10110  'rb' \'b1\'ea\'d6\'be\'d6\'b8\'c3\'f7\'d4\'da\'b6\'fe\'bd\'f8\'d6\'c6\'c4\'a3\'ca\'bd\'d6\'d0\'b6\'c1\'c8\'a1\'ce\'c4\'bc\'fe\'a1\'a3\
\
\'b1\'e0\'c2\'eb\'c4\'ac\'c8\'cf\'d6\'b5\'a3\'ba \'d2\'bb\'cd\'c5\'d4\'e3\
\'d3\'d0\'bc\'b8\'b8\'f6\'c9\'e8\'d6\'c3\'b6\'d4 Python I/O \'b5\'c4\'b1\'e0\'c2\'eb\'c4\'ac\'c8\'cf\'d6\'b5\'d3\'d0\'d3\'b0\'cf\'ec\'a3\'ac \'c8\'e7\'ca\'be\'c0\'fd 4-11 \'d6\'d0\'b5\'c4\
default_encodings.py \'bd\'c5\'b1\'be\'cb\'f9\'ca\'be\'a1\'a3\
\
\'ca\'be\'c0\'fd 4-11 \'cc\'bd\'cb\'f7\'b1\'e0\'c2\'eb\'c4\'ac\'c8\'cf\'d6\'b5\
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf3 \cb4 import\cf5  sys, locale
\f1\fs24 \cf0 \
\

\f2\fs28 \cf5 expressions = \cf6 """
\f1\fs24 \cf0 \

\f2\fs28 \cf6         locale.getpreferredencoding()
\f1\fs24 \cf0 \

\f2\fs28 \cf6         type(my_file)
\f1\fs24 \cf0 \

\f2\fs28 \cf6         my_file.encoding
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.stdout.isatty()
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.stdout.encoding
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.stdin.isatty()
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.stdin.encoding
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.stderr.isatty()
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.stderr.encoding
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.getdefaultencoding()
\f1\fs24 \cf0 \

\f2\fs28 \cf6         sys.getfilesystemencoding()
\f1\fs24 \cf0 \

\f2\fs28 \cf6     """
\f1\fs24 \cf0 \
\

\f2\fs28 \cf5 my_file = open(\cf7 'dummy'\cf5 , \cf7 'w'\cf5 )
\f1\fs24 \cf0 \
\

\f2\fs28 \cf3 for\cf5  expression \cf3 in\cf5  expressions.split():
\f1\fs24 \cf0 \

\f2\fs28 \cf5     value = eval(expression)
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf3 print\cf5 (expression.rjust(\cf7 30\cf5 ), \cf7 '->'\cf5 , repr(value))
\f0\fs36 \cf2 \cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 \
4.6 \'ce\'aa\'c1\'cb\'d5\'fd\'c8\'b7\'b1\'c8\'bd\'cf\'b6\'f8\'b9\'e6\'b7\'b6\'bb\'afUnicode\'d7\'d6\'b7\'fb\'b4\'ae\
>>> s1 = 'caf\'a8\'a6'\
>>> s2 = 'cafe\\u0301'\
>>> s1, s2\
('caf\'a8\'a6', 'caf\'a8\'a6')\
>>> len(s1), len(s2)\
(4, 5)\
>>> s1 == s2\
False\
\'ca\'b9\'d3\'c3 unicodedata.normalize \'ba\'af\'ca\'fd\'cc\'e1\'b9\'a9\'b5\'c4Unicode \'b9\'e6\'b7\'b6\'bb\'af\
\
NFC\'a3\'a8 Normalization Form C\'a3\'a9 \'ca\'b9\'d3\'c3\'d7\'ee\'c9\'d9\'b5\'c4\'c2\'eb\'ce\'bb\'b9\'b9\'b3\'c9\'b5\'c8\'bc\'db\'b5\'c4\'d7\'d6\'b7\'fb\'b4\'ae\'a3\'ac \'b6\'f8\
NFD \'b0\'d1\'d7\'e9\'ba\'cf\'d7\'d6\'b7\'fb\'b7\'d6\'bd\'e2\'b3\'c9\'bb\'f9\'d7\'d6\'b7\'fb\'ba\'cd\'b5\'a5\'b6\'c0\'b5\'c4\'d7\'e9\'ba\'cf\'d7\'d6\'b7\'fb\'a1\'a3\
>>> from unicodedata import normalize\
>>> s1 = 'caf\'a8\'a6' # \'b0\'d1"e"\'ba\'cd\'d6\'d8\'d2\'f4\'b7\'fb\'d7\'e9\'ba\'cf\'d4\'da\'d2\'bb\'c6\'f0\
>>> s2 = 'cafe\\u0301' # \'b7\'d6\'bd\'e2\'b3\'c9"e"\'ba\'cd\'d6\'d8\'d2\'f4\'b7\'fb\
>>> len(s1), len(s2)\
(4, 5)\
>>> len(normalize('NFC', s1)), len(normalize('NFC', s2))\
(4, 4)\
>>> len(normalize('NFD', s1)), len(normalize('NFD', s2))\
(5, 5)\
>>> normalize('NFC', s1) == normalize('NFC', s2)\
True\
>>> normalize('NFD', s1) == normalize('NFD', s2)\
True\
\
\'b0\'b2\'c8\'ab\'c6\'f0\'bc\'fb\'a3\'ac \'b1\'a3\'b4\'e6\'ce\'c4\'b1\'be\'d6\'ae\'c7\'b0\'a3\'ac \'d7\'ee\'ba\'c3\'ca\'b9\'d3\'c3 normalize('NFC',\
user_text) \'c7\'e5\'cf\'b4\'d7\'d6\'b7\'fb\'b4\'ae\'a1\'a3 NFC \'d2\'b2\'ca\'c7 W3C \'b5\'c4\'a1\'b0Character Model for the\
World Wide Web: String Matching and Searching\'a1\'b1\'b9\'e6\'b7\'b6\
\'a3\'a8 https://www.w3.org/TR/charmod-norm/\'a3\'a9 \'cd\'c6\'bc\'f6\'b5\'c4\'b9\'e6\'b7\'b6\'bb\'af\'d0\'ce\'ca\'bd\'a1\'a3\
\
\'ca\'b9\'d3\'c3 NFC \'ca\'b1\'a3\'ac\'b5\'e7\'d7\'e8\'b5\'c4\'b5\'a5\
\'ce\'bb\'c5\'b7\'c4\'b7\'a3\'a8 \'a6\'b8\'a3\'a9\'bb\'e1\'b1\'bb\'b9\'e6\'b7\'b6\'b3\'c9\'cf\'a3\'c0\'b0\'d7\'d6\'c4\'b8\'b4\'f3\'d0\'b4\'b5\'c4\'c5\'b7\'c3\'d7\'a3\'ac\'d2\'f2\'b4\'cb\'d2\'aa\'b9\'e6\'b7\'b6\'bb\'af\'a3\'ac \'b7\'c0\'d6\'b9\'b3\'f6\'cf\'d6\'d2\'e2\'cd\'e2\'a3\'ba\
>>> from unicodedata import normalize, name\
>>> ohm = '\\u2126'\
>>> name(ohm)\
'OHM SIGN'\
>>> ohm_c = normalize('NFC', ohm)\
>>> name(ohm_c)\
'GREEK CAPITAL LETTER OMEGA'\
>>> ohm == ohm_c\
False\
>>> normalize('NFC', ohm) == normalize('NFC', ohm_c)\
True\
\
\'d4\'da\'c1\'ed\'cd\'e2\'c1\'bd\'b8\'f6\'b9\'e6\'b7\'b6\'bb\'af\'d0\'ce\'ca\'bd\'a3\'a8 NFKC \'ba\'cd NFKD\'a3\'a9 \'b5\'c4\'ca\'d7\'d7\'d6\'c4\'b8\'cb\'f5\'c2\'d4\'b4\'ca\'d6\'d0\'a3\'ac \'d7\'d6\'c4\'b8 K\
\'b1\'ed\'ca\'be\'a1\'b0compatibility\'a1\'b1\'a3\'a8 \'bc\'e6\'c8\'dd\'d0\'d4\'a3\'a9 \'a1\'a3 \'d5\'e2\'c1\'bd\'d6\'d6\'ca\'c7\'bd\'cf\'d1\'cf\'b8\'f1\'b5\'c4\'b9\'e6\'b7\'b6\'bb\'af\'d0\'ce\'ca\'bd\'a3\'ac \'b6\'d4\'a1\'b0\'bc\'e6\
\'c8\'dd\'d7\'d6\'b7\'fb\'a1\'b1\'d3\'d0\'d3\'b0\'cf\'ec\'a1\'a3\
>>> from unicodedata import normalize, name\
>>> half = '\uc0\u189 '\
>>> normalize('NFKC', half)\
'1\uc0\u8260 2'\
>>> four_squared = '4\uc0\u178 '\
>>> normalize('NFKC', four_squared)\
'42'\
>>> micro = '\'a6\'cc'\
>>> micro_kc = normalize('NFKC', micro)\
>>> micro, micro_kc\
('\'a6\'cc', '\'a6\'cc')\
>>> ord(micro), ord(micro_kc)\
(181, 956)\
>>> name(micro), name(micro_kc)\
('MICRO SIGN', 'GREEK SMALL LETTER MU')\
\
NFKC \'bb\'f2 NFKD \'bf\'c9\'c4\'dc\'bb\'e1\'cb\'f0\'ca\'a7\'bb\'f2\'c7\'fa\'bd\'e2\'d0\'c5\'cf\'a2\'a3\'ac \'b5\'ab\'ca\'c7\'bf\'c9\'d2\'d4\'ce\'aa\'cb\'d1\'cb\'f7\'ba\'cd\
\'cb\'f7\'d2\'fd\'cc\'e1\'b9\'a9\'b1\'e3\'c0\'fb\'b5\'c4\'d6\'d0\'bc\'e4\'b1\'ed\'ca\'f6\'a3\'ba \'d3\'c3\'bb\'a7\'cb\'d1\'cb\'f7 '1 / 2 inch' \'ca\'b1\'a3\'ac \'c8\'e7\'b9\'fb\'bb\'b9\'c4\'dc\'d5\'d2\'b5\'bd\
\'b0\'fc\'ba\'ac '\uc0\u189  inch' \'b5\'c4\'ce\'c4\'b5\'b5\'a3\'ac \'c4\'c7\'c3\'b4\'d3\'c3\'bb\'a7\'bb\'e1\'b8\'d0\'b5\'bd\'c2\'fa\'d2\'e2\'a1\'a3\
\
\
4.6.1 \'b4\'f3\'d0\'a1\'d0\'b4\'d5\'db\'b5\'fe\
\'b4\'f3\'d0\'a1\'d0\'b4\'d5\'db\'b5\'fe\'c6\'e4\'ca\'b5\'be\'cd\'ca\'c7\'b0\'d1\'cb\'f9\'d3\'d0\'ce\'c4\'b1\'be\'b1\'e4\'b3\'c9\'d0\'a1\'d0\'b4\'a3\'ac \'d4\'d9\'d7\'f6\'d0\'a9\'c6\'e4\'cb\'fb\'d7\'aa\'bb\'bb\'a1\'a3 \'d5\'e2\'b8\'f6\'b9\'a6\'c4\'dc\
\'d3\'c9 str.casefold() \'b7\'bd\'b7\'a8\'a3\'a8 Python 3.3 \'d0\'c2\'d4\'f6\'a3\'a9 \'d6\'a7\'b3\'d6\'a1\'a3\
\
\'b6\'d4\'d3\'da\'d6\'bb\'b0\'fc\'ba\'ac latin1 \'d7\'d6\'b7\'fb\'b5\'c4\'d7\'d6\'b7\'fb\'b4\'ae s\'a3\'ac s.casefold() \'b5\'c3\'b5\'bd\'b5\'c4\'bd\'e1\'b9\'fb\'d3\'eb\
s.lower() \'d2\'bb\'d1\'f9\'a3\'ac \'ce\'a8\'d3\'d0\'c1\'bd\'b8\'f6\'c0\'fd\'cd\'e2\'a3\'ba \'ce\'a2\'b7\'fb\'ba\'c5 '\'a6\'cc' \'bb\'e1\'b1\'e4\'b3\'c9\'d0\'a1\'d0\'b4\'b5\'c4\'cf\'a3\'c0\'b0\'d7\'d6\
\'c4\'b8\'a1\'b0\'a6\'cc\'a1\'b1\'a3\'a8 \'d4\'da\'b6\'e0\'ca\'fd\'d7\'d6\'cc\'e5\'d6\'d0\'b6\'fe\'d5\'df\'bf\'b4\'c6\'f0\'c0\'b4\'d2\'bb\'d1\'f9\'a3\'a9 \'a3\'bb \'b5\'c2\'d3\'ef Eszett\'a3\'a8 \'a1\'b0sharp s\'a1\'b1\'a3\'ac \uc0\u223 \'a3\'a9\
\'bb\'e1\'b1\'e4\'b3\'c9\'a1\'b0ss\'a1\'b1\'a1\'a3\
\
>>> micro = '\'a6\'cc'\
>>> name(micro)\
'MICRO SIGN'\
>>> micro_cf = micro.casefold()\
>>> name(micro_cf)\
'GREEK SMALL LETTER MU'\
>>> micro, micro_cf\
('\'a6\'cc', '\'a6\'cc')\
>>> eszett = '\uc0\u223 '\
>>> name(eszett)\
'LATIN SMALL LETTER SHARP S'\
>>> eszett_cf = eszett.casefold()\
>>> eszett, eszett_cf\
('\uc0\u223 ', 'ss')\
\
4.6.2 \'b9\'e6\'b7\'b6\'bb\'af\'ce\'c4\'b1\'be\'c6\'a5\'c5\'e4\'ca\'b5\'d3\'c3\'ba\'af\'ca\'fd\
\'b6\'d4\'b4\'f3\'b6\'e0\'ca\'fd\'d3\'a6\'d3\'c3\'c0\'b4\'cb\'b5\'a3\'ac NFC \'ca\'c7\'d7\'ee\'ba\'c3\'b5\'c4\'b9\'e6\'b7\'b6\'bb\'af\'d0\'ce\'ca\'bd\'a1\'a3 \'b2\'bb\'c7\'f8\'b7\'d6\'b4\'f3\'d0\'a1\'d0\'b4\'b5\'c4\'b1\'c8\'bd\'cf\'d3\'a6\'b8\'c3\'ca\'b9\'d3\'c3 str.casefold()\'a1\'a3\
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf6 \cb4 """
\f1\fs24 \cf0 \

\f2\fs28 \cf6 Utility functions for normalized Unicode string comparison.
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6 Using Normal Form C, case sensitive:
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6     >>> s1 = 'caf\'e9'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> s2 = 'cafe\\u0301'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> s1 == s2
\f1\fs24 \cf0 \

\f2\fs28 \cf6     False
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> nfc_equal(s1, s2)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     True
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> nfc_equal('A', 'a')
\f1\fs24 \cf0 \

\f2\fs28 \cf6     False
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6 Using Normal Form C with case folding:
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6     >>> s3 = 'Stra\'dfe'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> s4 = 'strasse'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> s3 == s4
\f1\fs24 \cf0 \

\f2\fs28 \cf6     False
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> nfc_equal(s3, s4)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     False
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> fold_equal(s3, s4)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     True
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> fold_equal(s1, s2)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     True
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> fold_equal('A', 'a')
\f1\fs24 \cf0 \

\f2\fs28 \cf6     True
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6 """
\f1\fs24 \cf0 \
\

\f2\fs28 \cf3 from\cf5  unicodedata \cf3 import\cf5  normalize
\f1\fs24 \cf0 \
\

\f2\fs28 \cf3 def\cf5  nfc_equal(str1, str2):
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf3 return\cf5  normalize(\cf7 'NFC'\cf5 , str1) == normalize(\cf7 'NFC'\cf5 , str2)
\f1\fs24 \cf0 \
\

\f2\fs28 \cf3 def\cf5  fold_equal(str1, str2):
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf3 return\cf5  (normalize(\cf7 'NFC'\cf5 , str1).casefold() ==
\f1\fs24 \cf0 \

\f2\fs28 \cf5             normalize(\cf7 'NFC'\cf5 , str2).casefold())
\f1\fs24 \cf0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \cb1 \
\
4.6.3 \'bc\'ab\'b6\'cb\'a1\'b0\'b9\'e6\'b7\'b6\'bb\'af\'a1\'b1\'a3\'ba \'c8\'a5\'b5\'f4\'b1\'e4\'d2\'f4\'b7\'fb\'ba\'c5\
\'ca\'be\'c0\'fd 4-14 \'c8\'a5\'b5\'f4\'c8\'ab\'b2\'bf\'d7\'e9\'ba\'cf\'bc\'c7\'ba\'c5\'b5\'c4\'ba\'af\'ca\'fd\'a3\'a8 \'d4\'da sanitize.py \'c4\'a3\'bf\'e9\'d6\'d0\'a3\'a9\
\
import unicodedata\
import string\
def shave_marks(txt):\
	"""\'c8\'a5\'b5\'f4\'c8\'ab\'b2\'bf\'b1\'e4\'d2\'f4\'b7\'fb\'ba\'c5"""\
	norm_txt = unicodedata.normalize('NFD', txt) \uc0\u10122 \
	shaved = ''.join(c for c in norm_txt\
				if not unicodedata.combining(c)) \uc0\u10123 \
	return unicodedata.normalize('NFC', shaved) \uc0\u10124 \
\uc0\u10122  \'b0\'d1\'cb\'f9\'d3\'d0\'d7\'d6\'b7\'fb\'b7\'d6\'bd\'e2\'b3\'c9\'bb\'f9\'d7\'d6\'b7\'fb\'ba\'cd\'d7\'e9\'ba\'cf\'bc\'c7\'ba\'c5\'a1\'a3\
\uc0\u10123  \'b9\'fd\'c2\'cb\'b5\'f4\'cb\'f9\'d3\'d0\'d7\'e9\'ba\'cf\'bc\'c7\'ba\'c5\'a1\'a3\
\uc0\u10124  \'d6\'d8\'d7\'e9\'cb\'f9\'d3\'d0\'d7\'d6\'b7\'fb\'a1\'a3\
\
\'ca\'be\'c0\'fd 4-15 \'ca\'be\'c0\'fd 4-14 \'d6\'d0 shave_marks \'ba\'af\'ca\'fd\'b5\'c4\'c1\'bd\'b8\'f6\'ca\'b9\'d3\'c3\'ca\'be\'c0\'fd\
>>> order = '\'a1\'b0Herr Vo\uc0\u223 : \'a1\'a4 \u189  cup of OEtker\u8482  caff\'a8\'a8 latte \'a1\'a4 bowl of a\u231 a\'a8\'aa.\'a1\'b1'\
>>> shave_marks(order)\
'\'a1\'b0Herr Vo\uc0\u223 : \'a1\'a4 \u189  cup of OEtker\u8482  caffe latte \'a1\'a4 bowl of acai.\'a1\'b1' \u10122 \
>>> Greek = 'Z
\f3 \uc0\u941 
\f0 \'a6\'d5upo
\f3 \uc0\u962 
\f0 , Z\'a8\'a6firo'\
>>> shave_marks(Greek)\
'\'a6\'a6\'a6\'c5\'a6\'d5upo
\f3 \uc0\u962 
\f0 , Zefiro' \uc0\u10123 \
\
\uc0\u10122  \'d6\'bb\'cc\'e6\'bb\'bb\'c1\'cb\'a1\'b0\'a8\'a8\'a1\'b1\'a1\'b0\u231 \'a1\'b1\'ba\'cd\'a1\'b0\'a8\'aa\'a1\'b1\'c8\'fd\'b8\'f6\'d7\'d6\'b7\'fb\'a1\'a3\
\uc0\u10123  \'a1\'b0
\f3 \uc0\u941 
\f0 \'a1\'b1\'ba\'cd\'a1\'b0\'a8\'a6\'a1\'b1\'b6\'bc\'b1\'bb\'cc\'e6\'bb\'bb\'c1\'cb\'a1\'a3\
\
\'ca\'be\'c0\'fd 4-16 \'c9\'be\'b3\'fd\'c0\'ad\'b6\'a1\'d7\'d6\'c4\'b8\'d6\'d0\'d7\'e9\'ba\'cf\'bc\'c7\'ba\'c5\'b5\'c4\'ba\'af\'ca\'fd\'a3\'a8 import \'d3\'ef\'be\'e4\'ca\'a1\'c2\'d4\
\'c1\'cb\'a3\'ac \'d2\'f2\'ce\'aa\'d5\'e2\'ca\'c7\'ca\'be\'c0\'fd 4-14 \'d6\'d0\'b6\'a8\'d2\'e5\'b5\'c4 sanitize.py \'c4\'a3\'bf\'e9\'b5\'c4\'d2\'bb\'b2\'bf\'b7\'d6\'a3\'a9\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf6 \cb4 """
\f1\fs24 \cf0 \

\f2\fs28 \cf6 Radical folding and text sanitizing.
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6 Handling a string with `cp1252` symbols:
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6     >>> order = '\'93Herr Vo\'df: \'95 \'bd cup of \'8ctker\'99 caff\'e8 latte \'95 bowl of a\'e7a\'ed.\'94'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> shave_marks(order)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '\'93Herr Vo\'df: \'95 \'bd cup of \'8ctker\'99 caffe latte \'95 bowl of acai.\'94'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> shave_marks_latin(order)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '\'93Herr Vo\'df: \'95 \'bd cup of \'8ctker\'99 caffe latte \'95 bowl of acai.\'94'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> dewinize(order)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '"Herr Vo\'df: - \'bd cup of OEtker(TM) caff\'e8 latte - bowl of a\'e7a\'ed."'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> asciize(order)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '"Herr Voss: - 1
\f4 \uc0\u8260 
\f2 2 cup of OEtker(TM) caffe latte - bowl of acai."'
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6 Handling a string with Greek and Latin accented characters:
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6     >>> greek = '\uc0\u918 \u941 \u966 \u965 \u961 \u959 \u962 , Z\'e9firo'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> shave_marks(greek)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '\uc0\u918 \u949 \u966 \u965 \u961 \u959 \u962 , Zefiro'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> shave_marks_latin(greek)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '\uc0\u918 \u941 \u966 \u965 \u961 \u959 \u962 , Zefiro'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> dewinize(greek)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '\uc0\u918 \u941 \u966 \u965 \u961 \u959 \u962 , Z\'e9firo'
\f1\fs24 \cf0 \

\f2\fs28 \cf6     >>> asciize(greek)
\f1\fs24 \cf0 \

\f2\fs28 \cf6     '\uc0\u918 \u941 \u966 \u965 \u961 \u959 \u962 , Zefiro'
\f1\fs24 \cf0 \
\

\f2\fs28 \cf6 """
\f1\fs24 \cf0 \
\
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # BEGIN SHAVE_MARKS
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf3 import\cf5  unicodedata
\f1\fs24 \cf0 \

\f2\fs28 \cf3 import\cf5  string
\f1\fs24 \cf0 \
\
\

\f2\fs28 \cf3 def\cf5  shave_marks(txt):
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf6 """Remove all diacritic marks"""
\f1\fs24 \cf0 \

\f2\fs28 \cf5     norm_txt = unicodedata.normalize(\cf7 'NFD'\cf5 , txt)  \cf8 \cb4 # <1>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5     shaved = \cf7 ''\cf5 .join(c \cf3 for\cf5  c \cf3 in\cf5  norm_txt
\f1\fs24 \cf0 \

\f2\fs28 \cf5                      \cf3 if\cf5  \cf3 not\cf5  unicodedata.combining(c))  \cf8 \cb4 # <2>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5     \cf3 return\cf5  unicodedata.normalize(\cf7 'NFC'\cf5 , shaved)  \cf8 \cb4 # <3>
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # END SHAVE_MARKS
\f1\fs24 \cf0 \cb4 \
\

\f2\fs28 \cf8 \cb4 # BEGIN SHAVE_MARKS_LATIN
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf3 def\cf5  shave_marks_latin(txt):
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf6 """
\f0 \'b0\'d1\'c0\'ad\'b6\'a1\'bb\'f9\'d7\'d6\'b7\'fb\'d6\'d0\'cb\'f9\'d3\'d0\'b5\'c4\'b1\'e4\'d2\'f4\'b7\'fb\'ba\'c5\'c9\'be\'b3\'fd
\f2 """
\f1\fs24 \cf0 \

\f2\fs28 \cf5     norm_txt = unicodedata.normalize(\cf7 'NFD'\cf5 , txt)  \cf8 \cb4 # <1>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5     latin_base = False
\f1\fs24 \cf0 \

\f2\fs28 \cf5     keepers = []
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf3 for\cf5  c \cf3 in\cf5  norm_txt:
\f1\fs24 \cf0 \

\f2\fs28 \cf5         \cf3 if\cf5  unicodedata.combining(c) \cf3 and\cf5  latin_base:   \cf8 \cb4 # <2>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5             \cf3 continue\cf5   \cf8 \cb4 # 
\f0 \'ba\'f6\'c2\'d4\'c0\'ad\'b6\'a1\'bb\'f9\'d7\'d6\'b7\'fb\'c9\'cf\'b5\'c4\'b1\'e4\'d2\'f4\'b7\'fb\'ba\'c5
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5         keepers.append(c)                             \cf8 \cb4 # <3>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5         \cf8 \cb4 # 
\f0 \'c8\'e7\'b9\'fb\'b2\'bb\'ca\'c7\'d7\'e9\'ba\'cf\'d7\'d6\'b7\'fb\'a3\'ac
\f2  
\f0 \'c4\'c7\'be\'cd\'ca\'c7\'d0\'c2\'b5\'c4\'bb\'f9\'d7\'d6\'b7\'fb
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5         \cf3 if\cf5  \cf3 not\cf5  unicodedata.combining(c):              \cf8 \cb4 # <4>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5             latin_base = c \cf3 in\cf5  string.ascii_letters
\f1\fs24 \cf0 \

\f2\fs28 \cf5     shaved = \cf7 ''\cf5 .join(keepers)
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf3 return\cf5  unicodedata.normalize(\cf7 'NFC'\cf5 , shaved)   \cf8 \cb4 # <5>
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # END SHAVE_MARKS_LATIN\
\

\f5 \uc0\u10122 
\f2  
\f0 \'b0\'d1\'cb\'f9\'d3\'d0\'d7\'d6\'b7\'fb\'b7\'d6\'bd\'e2\'b3\'c9\'bb\'f9\'d7\'d6\'b7\'fb\'ba\'cd\'d7\'e9\'ba\'cf\'bc\'c7\'ba\'c5\'a1\'a3
\f2 \

\f5 \uc0\u10123 
\f2  
\f0 \'bb\'f9\'d7\'d6\'b7\'fb\'ce\'aa\'c0\'ad\'b6\'a1\'d7\'d6\'c4\'b8\'ca\'b1\'a3\'ac
\f2  
\f0 \'cc\'f8\'b9\'fd\'d7\'e9\'ba\'cf\'bc\'c7\'ba\'c5\'a1\'a3
\f2 \

\f5 \uc0\u10124 
\f2  
\f0 \'b7\'f1\'d4\'f2\'a3\'ac
\f2  
\f0 \'b1\'a3\'b4\'e6\'b5\'b1\'c7\'b0\'d7\'d6\'b7\'fb\'a1\'a3
\f2 \

\f5 \uc0\u10125 
\f2  
\f0 \'bc\'ec\'b2\'e2\'d0\'c2\'b5\'c4\'bb\'f9\'d7\'d6\'b7\'fb\'a3\'ac
\f2  
\f0 \'c5\'d0\'b6\'cf\'ca\'c7\'b2\'bb\'ca\'c7\'c0\'ad\'b6\'a1\'d7\'d6\'c4\'b8\'a1\'a3
\f2 \

\f5 \uc0\u10126 
\f2  
\f0 \'d6\'d8\'d7\'e9\'cb\'f9\'d3\'d0\'d7\'d6\'b7\'fb\'a1\'a3
\f1\fs24 \cf0 \cb4 \
\
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \'ca\'be\'c0\'fd
\f1  4-17 
\f0 \'b0\'d1\'d2\'bb\'d0\'a9\'ce\'f7\'ce\'c4\'d3\'a1\'cb\'a2\'d7\'d6\'b7\'fb\'d7\'aa\'bb\'bb\'b3\'c9
\f1  ASCII 
\f0 \'d7\'d6\'b7\'fb
\f1\fs24 \cf0 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # BEGIN ASCIIZE
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf5 single_map = str.maketrans(\cf6 """\'82\'83\'84\'86\'88\'8b\'91\'92\'93\'94\'95\'96\'97\'98\'9b"""\cf5 ,  \cf8 \cb4 # <1>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5                            \cf6 """'f"*^<''""---~>"""\cf5 )
\f1\fs24 \cf0 \
\

\f2\fs28 \cf5 multi_map = str.maketrans(\{  \cf8 \cb4 # <2>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5     \cf7 '\'80'\cf5 : \cf7 '<euro>'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf7 '\'85'\cf5 : \cf7 '...'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf7 '\'8c'\cf5 : \cf7 'OE'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf7 '\'99'\cf5 : \cf7 '(TM)'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf7 '\'9c'\cf5 : \cf7 'oe'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf7 '\'89'\cf5 : \cf7 '<per mille>'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf7 '\'87'\cf5 : \cf7 '**'\cf5 ,
\f1\fs24 \cf0 \

\f2\fs28 \cf5 \})
\f1\fs24 \cf0 \
\

\f2\fs28 \cf5 multi_map.update(single_map)  \cf8 \cb4 # <3>
\f1\fs24 \cf0 \cb4 \
\

\f2\fs28 \cf3 def\cf5  dewinize(txt):
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf6 """Replace Win1252 symbols with ASCII chars or sequences"""\
	"""
\f0 \'b0\'d1
\f2 Win1252
\f0 \'b7\'fb\'ba\'c5\'cc\'e6\'bb\'bb\'b3\'c9
\f2 ASCII
\f0 \'d7\'d6\'b7\'fb\'bb\'f2\'d0\'f2\'c1\'d0
\f2 """
\f1\fs24 \cf0 \

\f2\fs28 \cf5     \cf3 return\cf5  txt.translate(multi_map)  \cf8 \cb4 # <4>
\f1\fs24 \cf0 \cb4 \
\
\

\f2\fs28 \cf3 def\cf5  asciize(txt):
\f1\fs24 \cf0 \

\f2\fs28 \cf5     no_marks = shave_marks_latin(dewinize(txt))     \cf8 \cb4 # <5>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5     no_marks = no_marks.replace(\cf7 '\'df'\cf5 , \cf7 'ss'\cf5 )          \cf8 \cb4 # <6>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5     \cf3 return\cf5  unicodedata.normalize(\cf7 'NFKC'\cf5 , no_marks)  \cf8 \cb4 # <7>
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # END ASCIIZE
\f1\fs24 \cf0 \cb4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \cb1 \
\uc0\u10102  \'b9\'b9\'bd\'a8\'d7\'d6\'b7\'fb\'cc\'e6\'bb\'bb\'d7\'d6\'b7\'fb\'b5\'c4\'d3\'b3\'c9\'e4\'b1\'ed\'a1\'a3\
\uc0\u10103  \'b9\'b9\'bd\'a8\'d7\'d6\'b7\'fb\'cc\'e6\'bb\'bb\'d7\'d6\'b7\'fb\'b4\'ae\'b5\'c4\'d3\'b3\'c9\'e4\'b1\'ed\'a1\'a3\
\uc0\u10104  \'ba\'cf\'b2\'a2\'c1\'bd\'b8\'f6\'d3\'b3\'c9\'e4\'b1\'ed\'a1\'a3\
\uc0\u10105  dewinize \'ba\'af\'ca\'fd\'b2\'bb\'d3\'b0\'cf\'ec ASCII \'bb\'f2 latin1 \'ce\'c4\'b1\'be\'a3\'ac \'d6\'bb\'cc\'e6\'bb\'bb Microsoft \'d4\'da\
cp1252 \'d6\'d0\'ce\'aa latin1 \'b6\'ee\'cd\'e2\'cc\'ed\'bc\'d3\'b5\'c4\'d7\'d6\'b7\'fb\'a1\'a3\
\uc0\u10106  \'b5\'f7\'d3\'c3 dewinize \'ba\'af\'ca\'fd\'a3\'ac \'c8\'bb\'ba\'f3\'c8\'a5\'b5\'f4\'b1\'e4\'d2\'f4\'b7\'fb\'ba\'c5\'a1\'a3\
\uc0\u10107  \'b0\'d1\'b5\'c2\'d3\'ef Eszett \'cc\'e6\'bb\'bb\'b3\'c9\'a1\'b0ss\'a1\'b1\'a3\'a8 \'d5\'e2\'c0\'ef\'c3\'bb\'d3\'d0\'ca\'b9\'d3\'c3\'b4\'f3\'d0\'a1\'d0\'b4\'d5\'db\'b5\'fe\'a3\'ac \'d2\'f2\'ce\'aa\'ce\'d2\'c3\'c7\'cf\'eb\'b1\'a3\
\'c1\'f4\'b4\'f3\'d0\'a1\'d0\'b4\'a3\'a9 \'a1\'a3\
\uc0\u10108  \'ca\'b9\'d3\'c3 NFKC \'b9\'e6\'b7\'b6\'bb\'af\'d0\'ce\'ca\'bd\'b0\'d1\'d7\'d6\'b7\'fb\'ba\'cd\'d3\'eb\'d6\'ae\'bc\'e6\'c8\'dd\'b5\'c4\'c2\'eb\'ce\'bb\'d7\'e9\'ba\'cf\'c6\'f0\'c0\'b4\'a1\'a3\
\
\'ca\'be\'c0\'fd 4-18 \'ca\'be\'c0\'fd 4-17 \'d6\'d0 asciize \'ba\'af\'ca\'fd\'b5\'c4\'ca\'b9\'d3\'c3\'ca\'be\'c0\'fd\
\
>>> order = '\'a1\'b0Herr Vo\uc0\u223 : \'a1\'a4 \u189  cup of OEtker\u8482  caff\'a8\'a8 latte \'a1\'a4 bowl of a\u231 a\'a8\'aa.\'a1\'b1'\
>>> dewinize(order)\
'"Herr Vo\uc0\u223 : - \u189  cup of OEtker(TM) caff\'a8\'a8 latte - bowl of a\u231 a\'a8\'aa."' \u10122 \
>>> asciize(order)\
'"Herr Voss: - 1\uc0\u8260 2 cup of OEtker(TM) caffe latte - bowl of acai."' \u10123 \
\
\uc0\u10122  dewinize \'ba\'af\'ca\'fd\'cc\'e6\'bb\'bb\'cd\'e4\'d2\'fd\'ba\'c5\'a1\'a2 \'cf\'ee\'c4\'bf\'b7\'fb\'ba\'c5\'ba\'cd\u8482 \'a3\'a8 \'c9\'cc\'b1\'ea\'b7\'fb\'ba\'c5\'a3\'a9 \'a1\'a3\
\uc0\u10123  asciize \'ba\'af\'ca\'fd\'b5\'f7\'d3\'c3 dewinize \'ba\'af\'ca\'fd\'a3\'ac \'c8\'a5\'b5\'f4\'b1\'e4\'d2\'f4\'b7\'fb\'ba\'c5\'a3\'ac \'bb\'b9\'bb\'e1\'cc\'e6\'bb\'bb '\u223 '\'a1\'a3\
\
\
4.7 Unicode\'ce\'c4\'b1\'be\'c5\'c5\'d0\'f2\
\'d4\'da Python \'d6\'d0\'a3\'ac \'b7\'c7 ASCII \'ce\'c4\'b1\'be\'b5\'c4\'b1\'ea\'d7\'bc\'c5\'c5\'d0\'f2\'b7\'bd\'ca\'bd\'ca\'c7\'ca\'b9\'d3\'c3 locale.strxfrm\'ba\'af\'ca\'fd\'a3\'ac \'b8\'f9\'be\'dd locale \'c4\'a3\'bf\'e9\'b5\'c4\'ce\'c4\'b5\'b5\
\'a3\'a8 https://docs.python.org/3/library/locale.html?highlight=strxfrm#locale.strxfrm\'a3\'a9 \'a3\'ac \'d5\'e2 \'b8\'f6\'ba\'af\'ca\'fd\'bb\'e1\'a1\'b0\'b0\'d1\'d7\'d6\'b7\'fb\'b4\'ae\'d7\'aa\'bb\'bb\'b3\'c9\'ca\'ca\'ba\'cf\'cb\'f9\'d4\'da\'c7\'f8\'d3\'f2\'bd\'f8\'d0\'d0\'b1\'c8\'bd\'cf\'b5\'c4\'d0\'ce\'ca\'bd\'a1\'b1\'a1\'a3\
\
\'ca\'be\'c0\'fd 4-19 \'ca\'b9\'d3\'c3 locale.strxfrm \'ba\'af\'ca\'fd\'d7\'f6\'c5\'c5\'d0\'f2\'bc\'fc\
>>> import locale\
>>> locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\
'pt_BR.UTF-8'\
>>> fruits = ['caju', 'atemoia', 'caj\'a8\'a2', 'a\uc0\u231 a\'a8\'aa', 'acerola']\
>>> sorted_fruits = sorted(fruits, key=locale.strxfrm)\
>>> sorted_fruits\
['a\uc0\u231 a\'a8\'aa', 'acerola', 'atemoia', 'caj\'a8\'a2', 'caju']\
\
\'ca\'b9\'d3\'c3 locale.strxfrm \'ba\'af\'ca\'fd\'d7\'f6\'c5\'c5\'d0\'f2\'bc\'fc\'d6\'ae\'c7\'b0\'a3\'ac \'d2\'aa\'b5\'f7\'d3\'c3setlocale(LC_COLLATE, \uc0\u171 your_locale\u187 )\'a1\'a3\
\
\'d4\'da Linux \'b2\'d9\'d7\'f7\'cf\'b5\'cd\'b3\'d6\'d0\'a3\'ac \'d6\'d0\'b9\'fa\'b4\'f3\'c2\'bd\'b5\'c4\'b6\'c1\'d5\'df\'bf\'c9\'d2\'d4\'ca\'b9\'d3\'c3 zh_CN.UTF-8\'a3\'ac \'bc\'f2\'cc\'e5\'d6\'d0\'ce\'c4\'bb\'e1\'b0\'b4\'d5\'d5\'ba\'ba\'d3\'ef\'c6\'b4\'d2\'f4\'cb\'b3\'d0\'f2\'bd\'f8\'d0\'d0\'c5\'c5\'d0\'f2\
\
\'c7\'f8\'d3\'f2\'c9\'e8\'d6\'c3\'ca\'c7\'c8\'ab\'be\'d6\'b5\'c4\'a3\'ac \'d2\'f2\'b4\'cb\'b2\'bb\'cd\'c6\'bc\'f6\'d4\'da\'bf\'e2\'d6\'d0\'b5\'f7\'d3\'c3 setlocale \'ba\'af\'ca\'fd\'a1\'a3 \'d3\'a6\'d3\'c3\'bb\'f2\'bf\'f2\'bc\'dc\'d3\'a6\'b8\'c3\'d4\'da\'bd\'f8\'b3\'cc\'c6\'f4\'b6\'af\'ca\'b1\'c9\'e8\'b6\'a8\'c7\'f8\'d3\'f2\'c9\'e8\'d6\'c3\'a3\'ac \'b6\'f8\'c7\'d2\'b4\'cb\'ba\'f3\'b2\'bb\'d2\'aa\'d4\'d9\'d0\'de\'b8\'c4\'a1\'a3\
\'b2\'d9\'d7\'f7\'cf\'b5\'cd\'b3\'b1\'d8\'d0\'eb\'d6\'a7\'b3\'d6\'c7\'f8\'d3\'f2\'c9\'e8\'d6\'c3\'a3\'ac \'b7\'f1\'d4\'f2 setlocale \'ba\'af\'ca\'fd\'bb\'e1\'c5\'d7\'b3\'f6locale.Error: unsupported locale setting \'d2\'ec\'b3\'a3\'a1\'a3\
\
\cb9 PyPI \'d6\'d0\'b5\'c4 PyUCA \'bf\'e2\'a1\'a3\cb1 \
\
\'ca\'b9\'d3\'c3Unicode\'c5\'c5\'d0\'f2\'cb\'e3\'b7\'a8\'c5\'c5\'d0\'f2\
PyUCA \'bf\'e2\'a3\'a8 https://pypi.python.org/pypi/pyuca/\'a3\'a9 \
\
\'ca\'be\'c0\'fd 4-20 \'ca\'b9\'d3\'c3 pyuca.Collator.sort_key \'b7\'bd\'b7\'a8\
>>> import pyuca\
>>> coll = pyuca.Collator()\
>>> fruits = ['caju', 'atemoia', 'caj\'a8\'a2', 'a\uc0\u231 a\'a8\'aa', 'acerola']\
>>> sorted_fruits = sorted(fruits, key=coll.sort_key)\
>>> sorted_fruits\
['a\uc0\u231 a\'a8\'aa', 'acerola', 'atemoia', 'caj\'a8\'a2', 'caju']\
\
\'c8\'e7\'b9\'fb\'cf\'eb\'b6\'a8\'d6\'c6\'c5\'c5\'d0\'f2\'b7\'bd\'ca\'bd\'a3\'ac \'bf\'c9\'d2\'d4\'b0\'d1\'d7\'d4\'b6\'a8\'d2\'e5\'b5\'c4\'c5\'c5\'d0\'f2\'b1\'ed\'c2\'b7\'be\'b6\'b4\'ab\'b8\'f8 Collator() \'b9\'b9\'d4\'ec\'b7\'bd\'b7\'a8\'a1\'a3 PyUCA \'c4\'ac\'c8\'cf\'ca\'b9\'d3\'c3\'cf\'ee\'c4\'bf\'d7\'d4\'b4\'f8\'b5\'c4allkeys.txt\'a3\'a8 {\field{\*\fldinst{HYPERLINK "https://github.com/jtauber/pyuca"}}{\fldrslt https://github.com/jtauber/pyuca}}\'a3\'a9\
\
4.8 Unicode\'ca\'fd\'be\'dd\'bf\'e2\
\
\'ca\'be\'c0\'fd 4-21 Unicode \'ca\'fd\'be\'dd\'bf\'e2\'d6\'d0\'ca\'fd\'d6\'b5\'d7\'d6\'b7\'fb\'b5\'c4\'d4\'aa\'ca\'fd\'be\'dd\'ca\'be\'c0\'fd\'a3\'a8 \'b8\'f7\'b8\'f6\'b1\'ea\'ba\'c5\'cb\'b5\'c3\'f7\'ca\'e4\'b3\'f6\'d6\'d0\'b5\'c4\'b8\'f7\'c1\'d0\'a3\'a9\
import unicodedata\
import re\
re_digit = re.compile(r'\\d')\
sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\
for char in sample:\
	print('U+%04x' % ord(char), \uc0\u10122 \
		char.center(6), \uc0\u10123 \
		're_dig' if re_digit.match(char) else '-', \uc0\u10124 \
		'isdig' if char.isdigit() else '-', \uc0\u10125 \
		'isnum' if char.isnumeric() else '-', \uc0\u10126 \
		format(unicodedata.numeric(char), '5.2f'), \uc0\u10127 \
		unicodedata.name(char), \uc0\u10128 \
		sep='\\t')\
\uc0\u10122  U+0000 \'b8\'f1\'ca\'bd\'b5\'c4\'c2\'eb\'ce\'bb\'a1\'a3\
\uc0\u10123  \'d4\'da\'b3\'a4\'b6\'c8\'ce\'aa 6 \'b5\'c4\'d7\'d6\'b7\'fb\'b4\'ae\'d6\'d0\'be\'d3\'d6\'d0\'cf\'d4\'ca\'be\'d7\'d6\'b7\'fb\'a1\'a3\
\uc0\u10124  \'c8\'e7\'b9\'fb\'d7\'d6\'b7\'fb\'c6\'a5\'c5\'e4\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd r'\\d'\'a3\'ac \'cf\'d4\'ca\'be re_dig\'a1\'a3\
\uc0\u10125  \'c8\'e7\'b9\'fb char.isdigit() \'b7\'b5\'bb\'d8 True\'a3\'ac \'cf\'d4\'ca\'be isdig\'a1\'a3\
\uc0\u10126  \'c8\'e7\'b9\'fb char.isnumeric() \'b7\'b5\'bb\'d8 True\'a3\'ac \'cf\'d4\'ca\'be isnum\'a1\'a3\
\uc0\u10127  \'ca\'b9\'d3\'c3\'b3\'a4\'b6\'c8\'ce\'aa 5\'a1\'a2 \'d0\'a1\'ca\'fd\'b5\'e3\'ba\'f3\'b1\'a3\'c1\'f4 2 \'ce\'bb\'b5\'c4\'b8\'a1\'b5\'e3\'ca\'fd\'cf\'d4\'ca\'be\'ca\'fd\'d6\'b5\'a1\'a3\
\uc0\u10128  Unicode \'b1\'ea\'d7\'bc\'d6\'d0\'d7\'d6\'b7\'fb\'b5\'c4\'c3\'fb\'b3\'c6\'a1\'a3\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f2\fs22 \cf10 \cb11 \CocoaLigature0 U+0031	  1   	re_dig	isdig	isnum	 1.00	DIGIT ONE\
U+00bc	  \'bc   	-	-	isnum	 0.25	VULGAR FRACTION ONE QUARTER\
U+00b2	  \'b2   	-	isdig	isnum	 2.00	SUPERSCRIPT TWO\
U+0969	  
\f6 \uc0\u2409 
\f2    	re_dig	isdig	isnum	 3.00	DEVANAGARI DIGIT THREE\
U+136b	  
\f7 \uc0\u4971 
\f2    	-	isdig	isnum	 3.00	ETHIOPIC DIGIT THREE\
U+216b	  
\f3 \uc0\u8555 
\f2    	-	-	isnum	12.00	ROMAN NUMERAL TWELVE\
U+2466	  
\f0 \'a2\'df
\f2    	-	isdig	isnum	 7.00	CIRCLED DIGIT SEVEN\
U+2480	  
\f0 \'a2\'d1
\f2    	-	-	isnum	13.00	PARENTHESIZED NUMBER THIRTEEN\
U+3285	  
\f0 \uc0\u12933 
\f2    	-	-	isnum	 6.00	CIRCLED IDEOGRAPH SIX
\f0\fs36 \cf2 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 \'b1\'ea\'d7\'bc\'bf\'e2\'ce\'c4\'b5\'b5\'b6\'d4 unicodedata \'c4\'a3\'bf\'e9\'b5\'c4\'cb\'b5\'c3\'f7\'a3\'a8 {\field{\*\fldinst{HYPERLINK "https://docs.python.org/3/library/unicodedata.html"}}{\fldrslt https://docs.python.org/3/library/unicodedata.html}}\'a3\'a9 \'a1\'a3\
\
\'cb\'ab\'c4\'a3\'ca\'bd API\'a3\'ac \'bc\'b4\'cc\'e1\'b9\'a9\'b5\'c4\'ba\'af\'ca\'fd\'c4\'dc\'bd\'d3\'ca\'dc\'d7\'d6\'b7\'fb\'b4\'ae\'bb\'f2\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'ce\'aa\'b2\'ce\'ca\'fd\'a3\'ac \'c8\'bb\
\'ba\'f3\'b8\'f9\'be\'dd\'c0\'e0\'d0\'cd\'bd\'f8\'d0\'d0\'cc\'d8\'ca\'e2\'b4\'a6\'c0\'ed\'a1\'a3\
\
4.9 \'d6\'a7\'b3\'d6\'d7\'d6\'b7\'fb\'b4\'ae\'ba\'cd\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b5\'c4\'cb\'ab\'c4\'a3\'ca\'bdAPI\
\
\'ca\'be\'c0\'fd 4-22 ramanujan.py\'a3\'ba \'b1\'c8\'bd\'cf\'bc\'f2\'b5\'a5\'b5\'c4\'d7\'d6\'b7\'fb\'b4\'ae\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd\'ba\'cd\'d7\'d6\'bd\'da\'d0\'f2\
\'c1\'d0\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd\'b5\'c4\'d0\'d0\'ce\'aa\
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # BEGIN RE_DEMO
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf3 import\cf5  re
\f1\fs24 \cf0 \
\

\f2\fs28 \cf5 re_numbers_str = re.compile(r\cf7 '\\d+'\cf5 )     \cf8 \cb4 # <1>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5 re_words_str = re.compile(r\cf7 '\\w+'\cf5 )
\f1\fs24 \cf0 \

\f2\fs28 \cf5 re_numbers_bytes = re.compile(rb\cf7 '\\d+'\cf5 )  \cf8 \cb4 # <2>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5 re_words_bytes = re.compile(rb\cf7 '\\w+'\cf5 )
\f1\fs24 \cf0 \
\

\f2\fs28 \cf5 text_str = (\cf6 "Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef"\cf5   \cf8 \cb4 # <3>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf5             \cf6 " as 1729 = 1\'b3 + 12\'b3 = 9\'b3 + 10\'b3."\cf5 )        \cf8 \cb4 # <4>
\f1\fs24 \cf0 \cb4 \
\

\f2\fs28 \cf5 text_bytes = text_str.encode(\cf7 'utf_8'\cf5 )  \cf8 \cb4 # <5>
\f1\fs24 \cf0 \cb4 \
\

\f2\fs28 \cf3 print\cf5 (\cf7 'Text'\cf5 , repr(text_str), sep=\cf7 '\\n  '\cf5 )
\f1\fs24 \cf0 \

\f2\fs28 \cf3 print\cf5 (\cf7 'Numbers'\cf5 )
\f1\fs24 \cf0 \

\f2\fs28 \cf3 print\cf5 (\cf7 '  str  :'\cf5 , re_numbers_str.findall(text_str))      \cf8 \cb4 # <6>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf3 print\cf5 (\cf7 '  bytes:'\cf5 , re_numbers_bytes.findall(text_bytes))  \cf8 \cb4 # <7>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf3 print\cf5 (\cf7 'Words'\cf5 )
\f1\fs24 \cf0 \

\f2\fs28 \cf3 print\cf5 (\cf7 '  str  :'\cf5 , re_words_str.findall(text_str))        \cf8 \cb4 # <8>
\f1\fs24 \cf0 \cb4 \

\f2\fs28 \cf3 print\cf5 (\cf7 '  bytes:'\cf5 , re_words_bytes.findall(text_bytes))    \cf8 \cb4 # <9>
\f1\fs24 \cf0 \cb4 \
\pard\tx692\pardeftab692\pardirnatural\partightenfactor0

\f2\fs28 \cf8 \cb4 # END RE_DEMO
\f1\fs24 \cf0 \cb4 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf2 \cb1 \
\uc0\u10102  \'c7\'b0\'c1\'bd\'b8\'f6\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd\'ca\'c7\'d7\'d6\'b7\'fb\'b4\'ae\'c0\'e0\'d0\'cd\'a1\'a3\
\uc0\u10103  \'ba\'f3\'c1\'bd\'b8\'f6\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd\'ca\'c7\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'c0\'e0\'d0\'cd\'a1\'a3\
\uc0\u10104  \'d2\'aa\'cb\'d1\'cb\'f7\'b5\'c4 Unicode \'ce\'c4\'b1\'be\'a3\'ac \'b0\'fc\'c0\'a8 1729 \'b5\'c4\'cc\'a9\'c3\'d7\'b6\'fb\'ca\'fd\'d7\'d6\'a3\'a8 \'c2\'df\'bc\'ad\'d0\'d0\'d6\'b1\'b5\'bd\'d3\'d2\'c0\'a8\'ba\'c5\'b2\'c5\'bd\'e1\'ca\'f8\'a3\'a9 \'a1\'a3\
\uc0\u10105  \'d5\'e2\'b8\'f6\'d7\'d6\'b7\'fb\'b4\'ae\'d4\'da\'b1\'e0\'d2\'eb\'ca\'b1\'d3\'eb\'c7\'b0\'d2\'bb\'b8\'f6\'c6\'b4\'bd\'d3\'c6\'f0\'c0\'b4\'a3\'a8 \'b2\'ce\'bc\'fb Python \'d3\'ef\'d1\'d4\'b2\'ce\'bf\'bc\'ca\'d6\'b2\'e1\'d6\'d0\'b5\'c4\'a1\'b02.4.2. String literal\
concatenation\'a1\'b1\'a3\'ac https://docs.python.org/3/reference/lexical_analysis.html#stringliteral-concatenation\'a3\'a9 \'a1\'a3\
\uc0\u10106  \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'d6\'bb\'c4\'dc\'d3\'c3\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd\'cb\'d1\'cb\'f7\'a1\'a3\
\uc0\u10107  \'d7\'d6\'b7\'fb\'b4\'ae\'c4\'a3\'ca\'bd r'\\d+' \'c4\'dc\'c6\'a5\'c5\'e4\'cc\'a9\'c3\'d7\'b6\'fb\'ca\'fd\'d7\'d6\'ba\'cd ASCII \'ca\'fd\'d7\'d6\'a1\'a3\
\uc0\u10108  \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'c4\'a3\'ca\'bd rb'\\d+' \'d6\'bb\'c4\'dc\'c6\'a5\'c5\'e4 ASCII \'d7\'d6\'bd\'da\'d6\'d0\'b5\'c4\'ca\'fd\'d7\'d6\'a1\'a3\
\uc0\u10109  \'d7\'d6\'b7\'fb\'b4\'ae\'c4\'a3\'ca\'bd r'\\w+' \'c4\'dc\'c6\'a5\'c5\'e4\'d7\'d6\'c4\'b8\'a1\'a2 \'c9\'cf\'b1\'ea\'a1\'a2 \'cc\'a9\'c3\'d7\'b6\'fb\'ca\'fd\'d7\'d6\'ba\'cd ASCII \'ca\'fd\'d7\'d6\'a1\'a3\
\uc0\u10110  \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'c4\'a3\'ca\'bd rb'\\w+' \'d6\'bb\'c4\'dc\'c6\'a5\'c5\'e4 ASCII \'d7\'d6\'bd\'da\'d6\'d0\'b5\'c4\'d7\'d6\'c4\'b8\'ba\'cd\'ca\'fd\'d7\'d6\'a1\'a3\
\
\'d7\'d6\'b7\'fb\'b4\'ae\'d5\'fd\'d4\'f2\'b1\'ed\'b4\'ef\'ca\'bd\'d3\'d0\'b8\'f6 re.ASCII \'b1\'ea\'d6\'be\'a3\'ac \'cb\'fc\'c8\'c3\
\\w\'a1\'a2 \\W\'a1\'a2 \\b\'a1\'a2 \\B\'a1\'a2 \\d\'a1\'a2 \\D\'a1\'a2 \\s \'ba\'cd \\S \'d6\'bb\'c6\'a5\'c5\'e4 ASCII \'d7\'d6\'b7\'fb\'a1\'a3 \'cf\'ea\'c7\'e9\'b2\'ce\'d4\'c4 re\
\'c4\'a3\'bf\'e9\'b5\'c4\'ce\'c4\'b5\'b5\'a3\'a8 https://docs.python.org/3/library/re.html\'a3\'a9 \
\
4.9.2 os\'ba\'af\'ca\'fd\'d6\'d0\'b5\'c4\'d7\'d6\'b7\'fb\'b4\'ae\'ba\'cd\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\
\'ca\'be\'c0\'fd 4-23 \'b0\'d1\'d7\'d6\'b7\'fb\'b4\'ae\'ba\'cd\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'b2\'ce\'ca\'fd\'b4\'ab\'b8\'f8 listdir \'ba\'af\'ca\'fd\'b5\'c3\'b5\'bd\'b5\'c4\'bd\'e1\'b9\'fb\
\
>>> os.listdir('.') # \uc0\u10122 \
['abc.txt', 'digits-of-\'a6\'d0.txt']\
>>> os.listdir(b'.') # \uc0\u10123 \
[b'abc.txt', b'digits-of-\\xcf\\x80.txt']\
\
\uc0\u10122  \'b5\'da\'b6\'fe\'b8\'f6\'ce\'c4\'bc\'fe\'c3\'fb\'ca\'c7\'a1\'b0digits-of-\'a6\'d0.txt\'a1\'b1\'a3\'a8 \'d3\'d0\'d2\'bb\'b8\'f6\'cf\'a3\'c0\'b0\'d7\'d6\'c4\'b8 \'a6\'d0\'a3\'a9 \'a1\'a3\
\uc0\u10123  \'b2\'ce\'ca\'fd\'ca\'c7\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a3\'ac listdir \'ba\'af\'ca\'fd\'b7\'b5\'bb\'d8\'b5\'c4\'ce\'c4\'bc\'fe\'c3\'fb\'d2\'b2\'ca\'c7\'d7\'d6\'bd\'da\'d0\'f2\
\'c1\'d0\'a3\'ba b'\\xcf\\x80' \'ca\'c7\'cf\'a3\'c0\'b0\'d7\'d6\'c4\'b8 \'a6\'d0 \'b5\'c4 UTF-8 \'b1\'e0\'c2\'eb\'a1\'a3\
\
fsencode(filename)\
\'c8\'e7\'b9\'fb filename \'ca\'c7 str \'c0\'e0\'d0\'cd\'a3\'a8 \'b4\'cb\'cd\'e2\'bb\'b9\'bf\'c9\'c4\'dc\'ca\'c7 bytes \'c0\'e0\'d0\'cd\'a3\'a9 \'a3\'ac \'ca\'b9\'d3\'c3\
sys.getfilesystemencoding() \'b7\'b5\'bb\'d8\'b5\'c4\'b1\'e0\'bd\'e2\'c2\'eb\'c6\'f7\'b0\'d1 filename \'b1\'e0\'c2\'eb\'b3\'c9\
\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a3\'bb \'b7\'f1\'d4\'f2\'a3\'ac \'b7\'b5\'bb\'d8\'ce\'b4\'be\'ad\'d0\'de\'b8\'c4\'b5\'c4 filename \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a1\'a3\
\
fsdecode(filename)\
\'c8\'e7\'b9\'fb filename \'ca\'c7 bytes \'c0\'e0\'d0\'cd\'a3\'a8 \'b4\'cb\'cd\'e2\'bb\'b9\'bf\'c9\'c4\'dc\'ca\'c7 str \'c0\'e0\'d0\'cd\'a3\'a9 \'a3\'ac \'ca\'b9\'d3\'c3\
sys.getfilesystemencoding() \'b7\'b5\'bb\'d8\'b5\'c4\'b1\'e0\'bd\'e2\'c2\'eb\'c6\'f7\'b0\'d1 filename \'bd\'e2\'c2\'eb\'b3\'c9\
\'d7\'d6\'b7\'fb\'b4\'ae\'a3\'bb \'b7\'f1\'d4\'f2\'a3\'ac \'b7\'b5\'bb\'d8\'ce\'b4\'be\'ad\'d0\'de\'b8\'c4\'b5\'c4 filename \'d7\'d6\'b7\'fb\'b4\'ae\'a1\'a3\
\
\'ca\'be\'c0\'fd 4-24 \'ca\'b9\'d3\'c3 surrogateescape \'b4\'ed\'ce\'f3\'b4\'a6\'c0\'ed\'b7\'bd\'ca\'bd\
>>> os.listdir('.') \uc0\u10122 \
['abc.txt', 'digits-of-\'a6\'d0.txt']\
>>> os.listdir(b'.') \uc0\u10123 \
[b'abc.txt', b'digits-of-\\xcf\\x80.txt']\
>>> pi_name_bytes = os.listdir(b'.')[1] \uc0\u10124 \
>>> pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape') \uc0\u10125 \
>>> pi_name_str \uc0\u10126 \
'digits-of-\\udccf\\udc80.txt'\
>>> pi_name_str.encode('ascii', 'surrogateescape') \uc0\u10127 \
b'digits-of-\\xcf\\x80.txt\
\
\uc0\u10122  \'c1\'d0\'b3\'f6\'c4\'bf\'c2\'bc\'c0\'ef\'b5\'c4\'ce\'c4\'bc\'fe\'a3\'ac \'d3\'d0\'b8\'f6\'ce\'c4\'bc\'fe\'c3\'fb\'d6\'d0\'b0\'fc\'ba\'ac\'b7\'c7 ASCII \'d7\'d6\'b7\'fb\'a1\'a3\
\uc0\u10123  \'bc\'d9\'c9\'e8\'ce\'d2\'c3\'c7\'b2\'bb\'d6\'aa\'b5\'c0\'b1\'e0\'c2\'eb\'a3\'ac \'bb\'f1\'c8\'a1\'ce\'c4\'bc\'fe\'c3\'fb\'b5\'c4\'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'d0\'ce\'ca\'bd\'a1\'a3\
\uc0\u10124  pi_names_bytes \'ca\'c7\'b0\'fc\'ba\'ac \'a6\'d0 \'b5\'c4\'ce\'c4\'bc\'fe\'c3\'fb\'a1\'a3\
\uc0\u10125  \'ca\'b9\'d3\'c3'ascii' \'b1\'e0\'bd\'e2\'c2\'eb\'c6\'f7\'ba\'cd 'surrogateescape' \'b4\'ed\'ce\'f3\'b4\'a6\'c0\'ed\'b7\'bd\'ca\'bd\'b0\'d1\
\'cb\'fc\'bd\'e2\'c2\'eb\'b3\'c9\'d7\'d6\'b7\'fb\'b4\'ae\'a1\'a3\
\uc0\u10126  \'b8\'f7\'b8\'f6\'b7\'c7 ASCII \'d7\'d6\'bd\'da\'cc\'e6\'bb\'bb\'b3\'c9\'b4\'fa\'cc\'e6\'c2\'eb\'ce\'bb\'a3\'ba '\\xcf\\x80' \'b1\'e4\'b3\'c9\
\'c1\'cb'\\udccf\\udc80'\'a1\'a3\
\uc0\u10127  \'b1\'e0\'c2\'eb\'b3\'c9 ASCII \'d7\'d6\'bd\'da\'d0\'f2\'c1\'d0\'a3\'ba \'b8\'f7\'b8\'f6\'b4\'fa\'cc\'e6\'c2\'eb\'ce\'bb\'bb\'b9\'d4\'ad\'b3\'c9\'b1\'bb\'cc\'e6\'bb\'bb\'b5\'c4\'d7\'d6\'bd\'da\'a1\'a3\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
}